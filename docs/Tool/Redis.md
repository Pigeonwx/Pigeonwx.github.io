# Redis

## 背景

Redis（Remote Dictionary Server）是一个内存数据库，通常被称为键-值存储系统，它具有以下特点：

**特点：**
1. **内存数据库**：Redis的数据存储在内存中，因此读写速度非常快，是一种高性能的数据库系统。
2. **键-值存储**：Redis以键值对的形式存储数据，每个键都唯一，并且与一个值相关联。
3. **支持多种数据结构**：Redis支持多种数据结构，包括字符串、哈希、列表、集合、有序集合等，这使得它可以用于多种不同的应用场景。
4. **持久性**：Redis可以将数据持久化到磁盘上，以便在重启后数据不会丢失。
5. **分布式缓存**：Redis支持分布式缓存，可以用于构建高可用性和可伸缩性的应用程序。
6. **发布-订阅模式**：Redis支持发布-订阅模式，使得多个客户端可以订阅特定事件并接收通知。
7. **事务**：Redis支持事务操作，可以保证一系列操作的原子性。
8. **脚本支持**：Redis支持使用Lua脚本进行复杂的操作。

**与关系数据库（如MySQL）的异同：**
- **数据模型不同**：关系数据库使用表格模型，而Redis使用键-值模型。
- **查询语言不同**：关系数据库使用SQL进行查询，Redis使用命令行和API进行操作。
- **持久性**：关系数据库通常具有持久性，而Redis可以选择性地将数据持久化。
- **数据模型**：Redis支持多种数据结构，而关系数据库使用表格。
- **内存使用**：Redis存储在内存中，而关系数据库通常将数据存储在磁盘上。

**与非关系数据库（如MongoDB）的异同：**
- **数据模型不同**：MongoDB是一种文档型数据库，而Redis是键-值存储。
- **查询语言不同**：MongoDB使用JSON查询语言，而Redis使用命令行和API。
- **持久性**：MongoDB具有持久性，而Redis可以选择性地将数据持久化。
- **数据模型**：MongoDB支持复杂的文档结构，而Redis主要用于简单的键-值对。
- **主要用途**：MongoDB通常用于存储大量文档，而Redis主要用于缓存和处理高速数据。

总之，Redis是一个非常灵活的数据存储系统，适用于缓存、会话存储、队列等各种应用。它与传统的关系数据库和一些其他非关系数据库在数据模型、性能和使用场景上都有显著的差异。

### RQs

#### **Redis是单线程的，为什么还能这么快？**

**参考答案**

1. 对服务端程序来说，线程切换和锁通常是性能杀手，而单线程避免了线程切换和竞争所产生的消耗；
2. Redis的大部分操作是在内存上完成的，这是它实现高性能的一个重要原因；
3. Redis采用了IO多路复用机制，使其在网络IO操作中能并发处理大量的客户端请求，实现高吞吐率

#### **Redis在持久化时fork出一个子进程，这时已经有两个进程了，怎么能说是单线程呢？**

**参考答案**

Redis是单线程的，主要是指Redis的网络IO和键值对读写是由一个线程来完成的。而Redis的其他功能，如持久化、异步删除、集群数据同步等，则是依赖其他线程来执行的。所以，说Redis是单线程的只是一种习惯的说法，事实上它的底层不是单线程的。

**#### 说一下Redis中的watch命令**

**参考答案**

很多时候，要确保事务中的数据没有被其他客户端修改才执行该事务。Redis提供了watch命令来解决这类问题，这是一种乐观锁的机制。客户端通过watch命令，要求服务器对一个或多个key进行监视，如果在客户端执行事务之前，这些key发生了变化，则服务器将拒绝执行客户端提交的事务，并向它返回一个空值。

#### **要如何设计Redis的过期时间？**

**参考答案**

1. 热点数据不设置过期时间，使其达到“物理”上的永不过期，可以避免缓存击穿问题；
2. 在设置过期时间时，可以附加一个随机数，避免大量的key同时过期，导致缓存雪崩。

**#### Redis中，sexnx命令的返回值是什么，如何使用该命令实现分布式锁？**

setnx命令返回整数值，当返回1时表示设置值成果，当返回0时表示设置值失败（key已存在）。

一般我们不建议直接使用setnx命令来实现分布式锁，因为为了避免出现死锁，我们要给锁设置一个自动过期时间。而setnx命令和设置过期时间的命令不是原子的，可能加锁成果而设置过期时间失败，依然存在死锁的隐患。对于这种情况，Redis改进了set命令，给它增加了nx选项，启用该选项时set命令的效果就会setnx一样了。

采用Redis实现分布式锁，就是在Redis里存一份代表锁的数据，通常用字符串即可。采用改进后的setnx命令（即set...nx...命令）实现分布式锁的思路，以及优化的过程如下：

加锁：

第一版，这种方式的缺点是容易产生死锁，因为客户端有可能忘记解锁，或者解锁失败。

```
setnx key value
```

第二版，给锁增加了过期时间，避免出现死锁。但这两个命令不是原子的，第二步可能会失败，依然无法避免死锁问题。

```
setnx key value expire key seconds
```

第三版，通过“set...nx...”命令，将加锁、过期命令编排到一起，它们是原子操作了，可以避免死锁。

```
set key value nx ex seconds 
```

解锁：

解锁就是删除代表锁的那份数据。

```
del key
```

**优化**

1. 在加锁时就要给锁设置一个标识，进程要记住这个标识。当进程解锁的时候，要进行判断，是自己持有的锁才能释放，否则不能释放。可以为key赋一个随机值，来充当进程的标识。
2. 解锁时要先判断、再释放，这两步需要保证原子性，否则第二步失败的话，就会出现死锁。而获取和删除命令不是原子的，这就需要采用Lua脚本，通过Lua脚本将两个命令编排在一起，而整个Lua脚本的执行是原子的。

按照以上思路，优化后的命令如下：

```lua
# 加锁 set key random-value nx ex seconds   
# 解锁 if redis.call("get",KEYS[1]) == ARGV[1] then     return redis.call("del",KEYS[1]) else     return 0 end
```

**基于RedLock算法的分布式锁**

在单个主节点的架构上实现分布式锁，是无法保证高可用的。若要保证分布式锁的高可用，则可以采用多个节点的实现方案。这种方案有很多，而Redis的官方给出的建议是采用RedLock算法的实现方案。该算法基于多个Redis节点，它的基本逻辑如下：

- 这些节点相互独立，不存在主从复制或者集群协调机制；
- 加锁：以相同的KEY向N个实例加锁，只要超过一半节点成功，则认定加锁成功；
- 解锁：向所有的实例发送DEL命令，进行解锁；

我们可以自己实现该算法，也可以直接使用Redisson框架。

#### Redis为什么存的快，内存断电数据怎么恢复？

**参考答案**

Redis存的快是因为它的数据都存放在内存里，并且为了保证数据的安全性，Redis还提供了三种数据的持久化机制，即RDB持久化、AOF持久化、RDB-AOF混合持久化。若服务器断电，那么我们可以利用持久化文件，对数据进行恢复。理论上来说，AOF/RDB-AOF持久化可以将丢失数据的窗口控制在1S之内。

#### 说一说Redis的缓存淘汰策略

**参考答案**

当写入数据将导致超出maxmemory限制时，Redis会采用maxmemory-policy所指定的策略进行数据淘汰，该策略一共包含如下8种选项：

| **策略**        | **描述**                                                 | **版本** |
| --------------- | -------------------------------------------------------- | -------- |
| noeviction      | 直接返回错误；                                           |          |
| volatile-ttl    | 从设置了过期时间的键中，选择过期时间最小的键，进行淘汰； |          |
| volatile-random | 从设置了过期时间的键中，随机选择键，进行淘汰；           |          |
| volatile-lru    | 从设置了过期时间的键中，使用LRU算法选择键，进行淘汰；    |          |
| volatile-lfu    | 从设置了过期时间的键中，使用LFU算法选择键，进行淘汰；    | 4.0      |
| allleys-random  | 从所有的键中，随机选择键，进行淘汰；                     |          |
| allkeys-lru     | 从所有的键中，使用LRU算法选择键，进行淘汰；              |          |
| allkeys-lfu     | 从所有的键中，使用LFU算法选择键，进行淘汰；              | 4.0      |

#### 请介绍一下Redis的过期策略

**参考答案**

Redis支持如下两种过期策略：

惰性删除：客户端访问一个key的时候，Redis会先检查它的过期时间，如果发现过期就立刻删除这个key。

定期删除：Redis会将设置了过期时间的key放到一个独立的字典中，并对该字典进行每秒10次的过期扫描，过期扫描不会遍历字典中所有的key，而是采用了一种简单的贪心策略。该策略的删除逻辑如下：

1. 从过期字典中随机选择20个key；
2. 删除这20个key中已过期的key；
3. 如果已过期key的比例超过25%，则重复步骤1。



#### 缓存穿透、缓存击穿、缓存雪崩有什么区别，该如何解决？

缓存穿透、缓存击穿和缓存雪崩是与缓存相关的常见问题，它们有不同的原因和解决方法：

1. **缓存穿透**：
   - **问题**：缓存穿透是指针对某个不存在于缓存中的键不断发起请求，这些请求都会绕过缓存并直接查询数据库，导致数据库压力过大。
   - **解决方法**：通常有以下方法来减轻或解决缓存穿透问题：
     - 使用布隆过滤器等工具来过滤掉无效请求。
     - 当数据库中不存在对应数据时，也将一个"空值"存入缓存，设置较短的过期时间。
     - 针对特定的高请求频率的查询，可以采用预热缓存的方式，将这些热点数据提前加载到缓存中。

2. **缓存击穿**：
   - **问题**：缓存击穿是指某个热点数据在缓存中过期后，瞬间接收到大量请求，导致大量请求同时访问数据库，加重了数据库负载。
   - **解决方法**：缓存击穿的解决方法包括：
     - 使用互斥锁（Mutex Lock）来保护数据库访问，只允许一个线程去查询数据库，其他线程等待。
     - 设置较短的缓存过期时间，以减少大量请求同时访问数据库的可能性。
     - 在访问热点数据时，使用分布式锁或排他锁，确保只有一个请求可以重新加载数据到缓存。

3. **缓存雪崩**：
   - **问题**：缓存雪崩是指缓存中大量数据在相同的时间点过期，导致数据库压力剧增。
   - **解决方法**：缓存雪崩的解决方法包括：
     - 为不同的数据设置不同的过期时间，以避免所有数据在相同时间过期。
     - 使用缓存集群，确保缓存服务的高可用性，即使某一台服务器宕机，其他服务器仍能提供服务。
     - 使用持久化存储，如果缓存中的数据过期，可以从持久化存储中重新加载数据。

解决这些问题的方法通常需要根据具体的应用场景和需求来选择。综合使用预热缓存、布隆过滤器、分布式锁、不同的过期时间设置和高可用性等方法，可以有效地减轻或解决缓存穿透、缓存击穿和缓存雪崩问题。

#### 说一说你对布隆过滤器的理解

布隆过滤器可以用很低的代价，估算出数据是否真实存在。例如：给用户推荐新闻时，要去掉重复的新闻，就可以利用布隆过滤器，判断该新闻是否已经推荐过。

布隆过滤器的核心包括两部分：

1. 一个大型的位数组；
2. 若干个不一样的哈希函数，每个哈希函数都能将哈希值算的比较均匀。

布隆过滤器的工作原理：

1. 添加key时，每个哈希函数都利用这个key计算出一个哈希值，再根据哈希值计算一个位置，并将位数组中这个位置的值设置为1。
2. 询问key时，每个哈希函数都利用这个key计算出一个哈希值，再根据哈希值计算一个位置。然后对比这些哈希函数在位数组中对应位置的数值：
   - 如果这几个位置中，有一个位置的值是0，就说明这个布隆过滤器中，不存在这个key。
   - 如果这几个位置中，所有位置的值都是1，就说明这个布隆过滤器中，极有可能存在这个key。之所以不是百分之百确定，是因为也可能是其他的key运算导致该位置为1。

#### 如何保证redis 缓存和 数据库一致性？

> 想要保证缓存与数据库的双写一致，一共有4种方式，即4种同步策略：
>
> 先更新缓存，再更新数据库；先更新数据库，再更新缓存；先删除缓存，再更新数据库；先更新数据库，再删除缓存。从这4种同步策略中，我们需要作出比较的是：
>
> 更新缓存与删除缓存哪种方式更合适？应该先操作数据库还是先操作缓存？

- 最优：
- **更新缓存**

优点：每次数据变化都及时更新缓存，所以查询时不容易出现未命中的情况。

缺点：更新缓存的消耗比较大。如果数据需要经过复杂的计算再写入缓存，那么频繁的更新缓存，就会影响服务器的性能。如果是写入数据频繁的业务场景，那么可能频繁的更新缓存时，却没有业务读取该数据。

- **删除缓存**

优点：操作简单，无论更新操作是否复杂，都是将缓存中的数据直接删除。

缺点：删除缓存后，下一次查询缓存会出现未命中，这时需要重新读取一次数据库。从上面的比较来看，一般情况下，删除缓存是更优的方案。

**优化**

- 延时双删
  - 上面我们提到，如果是先删缓存、再更新数据库，在没有出现失败时可能会导致数据的不一致。如果在实际的应用中，出于某些考虑我们需要选择这种方式，那有办法解决这个问题吗？答案是有的，那就是采用延时双删的策略，延时双删的基本思路如下：**删除缓存；更新数据库；sleep N毫秒；再次删除缓存。**
- **缓存失效策略**：选择适当的TTL（Time-To-Live）来控制缓存的数据有效期
- **延时双写**：在一些情况下，可以采用延时双写策略。即，在更新数据库后，不立即更新缓存，而是等待一段时间后再更新缓存。这种方式可以有效减少缓存与数据库的频繁双写操作。
- **通过消息队列实现双写**：将数据库写和缓存写的操作发布到消息队列中，由消息队列负责异步更新数据库和缓存。这种方式可以提高系统的响应速度，同时保持双写一致性。
- **使用缓存中间件**：一些缓存中间件（如Redis）提供了事务支持，可以通过事务来确保缓存与数据库的一致性。在事务中，要么数据库和缓存同时成功，要么都回滚。
- **版本控制**：为每个数据项维护一个版本号，当更新数据库时，同时更新版本号。缓存中的数据也包含版本号，每次查询时比较版本号，如果不一致，则重新加载数据。
- **双写检查**：在更新缓存之前，首先检查数据库操作是否成功。如果数据库更新失败，不更新缓存，以确保数据库和缓存的一致性。
- **缓存回写**：周期性地或在特定条件下，将缓存中的数据回写到数据库，以确保数据的一致性。
- **数据同步工具**：使用专门的数据同步工具来同步数据库和缓存中的数据。

## 基本数据结构

###  字符串

> String 是redis最基本的类型，value 不仅可以是 String,也可以是数字。使用 Strings 类型,可以完全实现目前 Memcached 的功能,并且效率更高。还可以享受 Redis 的定时持久化(可以选择 RDB 模式或者 AOF 模式).string类型是二进制安全的。意思是redis的string可以包含任何数据,比如jpg图片或者序列化的对象string类型是Redis最基本的数据类型，一个键最大能存储512MB

**命令示例**

```shell
set ­­ 设置key对应的值为string类型的value。

> set name itcast
setnx ­­ 将key设置值为value，如果key不存在，这种情况下等同SET命令。 当key存在时，什么也不做。SETNX是”SET if Not eXists”的简写。

> get name
"itcast"
> setnx name itcast_new
(integer)0
>get name
"itcast"
========================================
setex ­­ 设置key对应字符串value，并且设置key在给定的seconds时间之后超时过期。

> setex color 10 red 
> get color
"red"
10秒后...
> get color (nil)
========================================
setrange ­­ 覆盖key对应的string的一部分，从指定的offset处开始，覆盖value的长度
> SET key1 "Hello World"
OK
> SETRANGE key1 6 "Redis"
(integer) 11
> GET key1
"Hello Redis"
========================================
mset ­­ 一次设置多个key的值,成功返回ok表示所有的值都设置了,失败返回0表示没有任何值被设置。

> mset key1 python key2 c++
  OK
mget ­­ 一次获取多个key的值,如果对应key不存在,则对应返回nil。

> mget key1 key2 key3
  1) "python"   
  2) "c++"   
  3) (nil)
========================================
msetnx ­­ 对应给定的keys到他们相应的values上。只要有一个key已经存在，MSETNX一个操作都不会执行。

> MSETNX key11 "Hello" key22 "there"
(integer) 1
> MSETNX key22 "there" key33 "world"
(integer) 0
认证了：MSETNX是原子的，所以所有给定的keys是一次性set的
========================================
GETRANGE key start end ­­ 获取指定key的value值的子字符串。是由start和end位移决定的

> getrange name 0 4
  "itcas"
========================================
incr ­­ 对key的值加1操作

> set age 20 
> incr age 
(integer) 21

incrby ­­ 同incr类似,加指定值 ,key不存在时候会设置key,并认为原来的value是 0

> incrby age 5
  (integer) 26
> incrby age1111 5
(integer) 5
> get age1111
"5"
decr ­­ 对key的值做的是减减操作,decr一个不存在key,则认为原来的value是 0

decrby ­­ 同decr,减指定值
========================================
append ­­ 给指定key的字符串值追加value,返回新字符串值的长度。例如我们向name的值追加一个"redis"字符串:

> get name
"itcast_new"
> append name "value"
(integer) 15
> get name
"itcast_newvalue"
>
```

### Hash

> Redis hash 是一个string类型的field和value的映射表，hash特别适合用于存储对象。
>
> Redis 中每个 hash 可以存储 2^32 - 1 键值对（40多亿）。

#### 底层实现

哈希对象有两种编码方案，当同时满足以下条件时，哈希对象采用ziplist编码，否则采用hashtable编码：

- 哈希对象保存的键值对数量小于512个；
- 哈希对象保存的所有键值对中的键和值，其字符串长度都小于64字节。

其中，ziplist编码采用压缩列表作为底层实现，而hashtable编码采用字典作为底层实现。

**压缩列表：**

压缩列表（ziplist），是Redis为了节约内存而设计的一种线性数据结构，它是由一系列具有特殊编码的连续内存块构成的。一个压缩列表可以包含任意多个节点，每个节点可以保存一个字节数组或一个整数值。ziplist是一种紧凑的数据结构，将多个字段和值存储在一个线性的内存区域中。ziplist对于小型Hash结构来说非常高效，因为它减少了指针和散列冲突等额外开销。每个字段和值对都被存储为一个紧凑的二进制串。

压缩列表的结构如下图所示：

![截屏2023-10-14 13.02.23](/Users/xiangjianhang/Downloads/LN/Redis/截屏2023-10-14 13.02.23.png)

**命令示例**

```shell
HSET key field value ­­ 设置 key 指定的哈希集中指定字段的值

> hset myhash field1 Hello
hget ­­ 获取指定的hash field。

> hget myhash field1  
 "Hello"
> hget myhash field3  
 (nil)
由于数据库没有field3,所以取到的是一个空值nil.
========================================
HSETNX key field value ­­ 只在 key 指定的哈希集中不存在指定的字段时，设置字段的值。如果 key 指定的哈希集不存在，会创建一个新的哈希集并与 key 关联。如果字段已存在，该操作无效果。

> hsetnx myhash field "Hello"   
(integer) 1
> hsetnx myhash field "Hello"   
(integer) 0
第一次执行是成功的,但第二次执行相同的命令失败,原因是field已经存在了。
========================================
hmset ­­ 同时设置hash的多个field。

> hmset myhash field1 Hello field2 World   
> OK
hmget ­­ 获取全部指定的hash filed。

> hmget myhash field1 field2 field3   
1) "Hello"
2) "World"
3) (nil)
========================================
hincrby ­­ 指定的hash filed 加上给定值。

> hset myhash field3 20  
 (integer) 1
> hget myhash field3  
 "20"
> hincrby myhash field3 -8   
(integer) 12
> hget myhash field3   
"12
========================================
hexists ­­ 测试指定field是否存在。

> hexists myhash field1
  (integer) 1
> hexists myhash field9
  (integer) 0   
通过上例可以说明field1存在,但field9是不存在的。
========================================
hdel 从 key 指定的哈希集中移除指定的域

> hkeys myhash
1) "field1"
2) "field"
3) "field2"
4) "field3"
> hdel myhash field
(integer) 1
> hkeys myhash
1) "field1"
2) "field2"
3) "field3"
========================================
hlen ­­ 返回指定hash的field数量。

> hlen myhash
  (integer) 3
hkeys ­­ 返回hash的所有field。

> hkeys myhash   
> 1) "field2"   
> 2) "field"   
> 3) "field3"
说明这个hash中有3个field。
========================================
hvals ­­ 返回hash的所有value。

> hvals myhash   
1) "World"   
2)"Hello"   
3)"12"
说明这个hash中有3个field。
========================================
hgetall ­­ 获取某个hash中全部的filed及value。

> hgetall myhash   
1) "field2"   
2) "World" 
3) "field"  
4) "Hello"   
5) "field3"   
6) "12"
========================================
HSTRLEN -- 返回 hash指定field的value的字符串长度

127.0.0.1:6379> HSTRLEN myhash field1
(integer) 5
```

### List

> Redis列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素导列表的头部（左边）或者尾部（右边）
>
> 一个列表最多可以包含 232 - 1 个元素 (4294967295, 每个列表超过40亿个元素)。

**命令示例**

```shell
RPUSH key value [value ...]

向存于 key 的列表的尾部插入所有指定的值。如果 key 不存在，那么会创建一个空的列表然后再进行 push 操作。

redis> RPUSH mylist "hello"
(integer) 1
redis> RPUSH mylist "world"
(integer) 2
redis> LRANGE mylist 0 -1
1) "hello"
2) "world"
========================================
 LPOP key
 移除并且返回 key 对应的 list 的第一个元素。

redis> RPUSH mylist "one"
(integer) 1
redis> RPUSH mylist "two"
(integer) 2
redis> RPUSH mylist "three"
(integer) 3
redis> LPOP mylist
"one"
redis> LRANGE mylist 0 -1
1) "two"
2) "three"
redis>
========================================
LTRIM key start stop
修剪(trim)一个已存在的 list，这样 list 就会只包含指定范围的指定元素。

> start 和 stop 都是由0开始计数的， 这里的 0 是列表里的第一个元素（表头），1 是第二个元素，以此类推。

例如： LTRIM foobar 0 2 将会对存储在 foobar 的列表进行修剪，只保留列表里的前3个元素。

start 和 end 也可以用负数来表示与表尾的偏移量，比如 -1 表示列表里的最后一个元素， -2 表示倒数第二个，等等。

```

**应用场景**:

1.取最新N个数据的操作

比如典型的取你网站的最新文章，通过下面方式，我们可以将最新的5000条评论的ID放在Redis的List集合中，并将超出集合部分从数据库获取

- 使用LPUSH latest.comments命令，向list集合中插入数据

- 插入完成后再用LTRIM latest.comments 0 5000命令使其永远只保存最近5000个ID

- 然后我们在客户端获取某一页评论时可以用下面的逻辑（伪代码）

  ```java
  FUNCTION get_latest_comments(start,num_items):
    id_list = redis.lrange("latest.comments",start,start+num_items-1)
    IF id_list.length < num_items
        id_list = SQL_DB("SELECT ... ORDER BY time LIMIT ...")
    END
    RETURN id_list
  ```

  如果你还有不同的筛选维度，比如某个分类的最新N条，那么你可以再建一个按此分类的List，只存ID的话，Redis是非常高效的。

**示例**

取最新N个评论的操作

```bash
127.0.0.1:6379> lpush mycomment 100001
(integer) 1
127.0.0.1:6379> lpush mycomment 100002
(integer) 2
127.0.0.1:6379> lpush mycomment 100003
(integer) 3
127.0.0.1:6379> lpush mycomment 100004
(integer) 4
127.0.0.1:6379> LRANGE mycomment 0 -1
1) "100004"
2) "100003"
3) "100002"
4) "100001"
127.0.0.1:6379> LTRIM mycomment 0 1
OK
127.0.0.1:6379> LRANGE mycomment 0 -1
1) "100004"
2) "100003"
127.0.0.1:6379> lpush mycomment 100005
(integer) 3
127.0.0.1:6379> LRANGE mycomment 0 -1
1) "100005"
2) "100004"
3) "100003"
127.0.0.1:6379> LTRIM mycomment 0 1
OK
127.0.0.1:6379> LRANGE mycomment 0 -1
1) "100005"
2) "100004"
127.0.0.1:6379>
```

###  Set

> Set 就是一个集合,集合的概念就是一堆不重复值的组合。利用 Redis 提供的 Set 数据结构,可以存储一些集合性的数据。比如在 微博应用中,可以将一个用户所有的关注人存在一个集合中,将其所有粉丝存在一个集合。

因为 Redis 非常人性化的为集合提供了 求交集、并集、差集等操作, 那么就可以非常方便的实现如共同关注、共同喜好、二度好友等功能, 对上面的所有集合操作,你还可以使用不同的命令选择将结果返回给客户端还是存集到一个新的集合中。

``` shell
SADD key member [member ...]
添加一个或多个指定的member元素到集合的 key中
redis> SADD myset "Hello"
(integer) 1
redis> SADD myset "World"
(integer) 1
redis> SADD myset "World"
(integer) 0
redis> SMEMBERS myset
1) "World"
2) "Hello"
========================================
SCARD key
返回集合存储的key的基数 (集合元素的数量).


redis> SADD myset "Hello"
(integer) 1
redis> SADD myset "World"
(integer) 1
redis> SCARD myset
(integer) 2
========================================
SDIFF key [key ...]
返回一个集合与给定集合的差集的元素.

redis> SADD key1 'a' 'b' 'c'
(integer) 1
redis> SADD key2 "c"
(integer) 1
redis> SADD key2 "d"
(integer) 1
redis> SADD key2 "e"
(integer) 1
redis> SDIFF key1 key2
1) "a"
2) "b"

```

**应用场景**

1.共同好友、二度好友

2.利用唯一性,可以统计访问网站的所有独立 IP

3.好友推荐的时候,根据 tag 求交集,大于某个 临界值 就可以推荐

**示例**

以王宝强和马蓉为例，求二度好友，共同好友，推荐系统

```shell
127.0.0.1:6379> sadd marong_friend 'songdan' 'wangsicong' 'songzhe'
(integer) 1
127.0.0.1:6379> SMEMBERS marong_friend
1) "songzhe"
2) "wangsicong"
3) "songdandan"
127.0.0.1:6379> sadd wangbaoqiang_friend 'dengchao' 'angelababy' 'songzhe'
(integer) 1

#求共同好友
127.0.0.1:6379> SINTER marong_friend wangbaoqiang_friend
1) "songzhe"

#推荐好友系统
127.0.0.1:6379> SDIFF marong_friend wangbaoqiang_friend
1) "wangsicong"
2) "songdandan"
```

### Zset

> Redis 有序集合和集合一样也是 string 类型元素的集合,且不允许重复的成员。不同的是每个元素都会关联一个 double 类型的分数。redis 正是通过分数来为集合中的成员进行从小到大的排序。
>
> **有序集合的成员是唯一的,但分数(score)却可以重复。**
>
> 集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。 集合中最大的成员数为 2^32 - 1 (4294967295, 每个集合可存储40多亿个成员)。

#### 底层实现

Redis有序集合（Sorted Set）的底层实现通常使用跳表（Skip List）和字典的结合。这种数据结构的设计使得有序集合在插入、删除和查找元素时都能够在O(log N)的时间复杂度内完成，其中N是有序集合中的元素数量。

有序集合的底层数据结构主要包括两部分：

1. **跳表（Skip List）**：跳表是一种类似于平衡树的数据结构，但相对简单。它包含多层链表，其中底层链表包含所有元素，而每个更高级别的链表都是前一个链表的子集。这种结构允许快速查找，插入和删除元素。跳表的高度是对数级别的，使得查找操作非常高效。

2. **字典**：在Redis的有序集合中，每个元素都有一个关联的分数（score）和一个成员（member）。字典用于存储这两部分信息，其中分数用于排序，成员用于唯一标识每个元素。字典是一种哈希表，可以实现快速的成员查找，但无法按照分值排序。因此，Redis使用字典来存储成员到分值的映射关系。同时，为了实现按分值排序，Redis使用跳跃表。

当执行有序集合的插入、删除或查找操作时，Redis会在跳表中执行这些操作以保持元素的有序性。同时，哈希表用于存储元素的具体数据。这种底层数据结构的设计允许Redis在插入、删除和查找元素时保持较低的时间复杂度，同时保持元素的有序性，使得有序集合非常适合用于排行榜、计分系统和其他需要元素有序性的应用。字典和哈希表的结合是Redis实现有序集合高效的关键因素。

**跳表结构**

![截屏2023-10-14 13.06.16](/Users/xiangjianhang/Downloads/LN/Redis/截屏2023-10-14 13.06.16.png)

**字典**

字典（dict）又称为散列表，是一种用来存储键值对的数据结构。C语言没有内置这种数据结构，所以Redis构建了自己的字典实现。Redis字典的实现主要涉及三个结构体：字典、哈希表、哈希表节点。其中，每个哈希表节点保存一个键值对，每个哈希表由多个哈希表节点构成，而字典则是对哈希表的进一步封装。这三个结构体的关系如下图所示：

![截屏2023-10-14 13.13.50](/Users/xiangjianhang/Downloads/LN/Redis/截屏2023-10-14 13.13.50.png)

其中，dict代表字典，dictht代表哈希表，dictEntry代表哈希表节点。可以看出，dictEntry是一个数组，这很好理解，因为一个哈希表里要包含多个哈希表节点。而dict里包含2个dictht，多出的哈希表用于REHASH。当哈希表保存的键值对数量过多或过少时，需要对哈希表的大小进行扩展或收缩操作，在Redis中，扩展和收缩哈希表是通过REHASH实现的，执行REHASH的大致步骤如下：

1. 为字典的ht[1]哈希表分配内存空间

   如果执行的是扩展操作，则ht[1]的大小为第1个大于等于ht[0].used*2的2n。如果执行的是收缩操作，则ht[1]的大小为第1个大于等于ht[0].used的2n。

2. 将存储在ht[0]中的数据迁移到ht[1]上

   重新计算键的哈希值和索引值，然后将键值对放置到ht[1]哈希表的指定位置上。

3. 将字典的ht[1]哈希表晋升为默认哈希表

   迁移完成后，清空ht[0]，再交换ht[0]和ht[1]的值，为下一次REHASH做准备。

当满足以下任何一个条件时，程序会自动开始对哈希表执行扩展操作：

1. 服务器目前没有执行bgsave或bgrewriteof命令，并且哈希表的负载因子大于等于1；
2. 服务器目前正在执行bgsave或bgrewriteof命令，并且哈希表的负载因子大于等于5。

为了避免REHASH对服务器性能造成影响，REHASH操作不是一次性地完成的，而是分多次、渐进式地完成的。渐进式REHASH的详细过程如下：

1. 为ht[1]分配空间，让字典同时持有ht[0]和ht[1]两个哈希表；
2. 在字典中的索引计数器rehashidx设置为0，表示REHASH操作正式开始；
3. 在REHASH期间，每次对字典执行添加、删除、修改、查找操作时，程序除了执行指定的操作外，还会顺带将ht[0]中位于rehashidx上的所有键值对迁移到ht[1]中，再将rehashidx的值加1；
4. 随着字典不断被访问，最终在某个时刻，ht[0]上的所有键值对都被迁移到ht[1]上，此时程序将rehashidx属性值设置为-1，标识REHASH操作完成。

REHSH期间，字典同时持有两个哈希表，此时的访问将按照如下原则处理：

1. 新添加的键值对，一律被保存到ht[1]中；
2. 删除、修改、查找等其他操作，会在两个哈希表上进行，即程序先尝试去ht[0]中访问要操作的数据，若不存在则到ht[1]中访问，再对访问到的数据做相应的处理。

**为什么使用字典+跳跃表**

![202003141840388](/Users/xiangjianhang/Downloads/LN/Redis/202003141840388.png)

**跳表VS红黑树**

跳表（Skip List）和红黑树（Red-Black Tree）是两种常见的数据结构，它们都用于实现有序集合，但具有不同的特点和适用场景。

**跳表（Skip List）:**

- 优点：
  1. 跳表相对简单，容易实现和维护。
  2. 在插入、删除和查找操作上具有良好的平均时间复杂度，通常为 O(log n)。
  3. 跳表是概率性数据结构，不需要旋转操作，因此没有像红黑树那样的平衡维护成本。
  4. 跳表在多核 CPU 上有良好的并行性，因为不需要像红黑树那样复杂的旋转操作。

- 缺点：
  1. 跳表需要占用更多的内存空间，因为它使用多层索引，不适用于内存有限的场景。
  2. 跳表相对于红黑树来说，不是自平衡的，因此插入和删除操作可能需要更多的成本。
  3. 跳表的实现相对复杂，需要维护多层索引，不如红黑树直观。

**红黑树（Red-Black Tree）:**

- 优点：
  1. 红黑树相对紧凑，节省内存，适用于内存有限的场景。
  2. 红黑树是自平衡的，插入和删除操作的性能更加可控，通常为 O(log n)。
  3. 红黑树在单核 CPU 上表现稳定，适用于单线程的应用。

- 缺点：
  1. 红黑树在多核 CPU 上可能存在性能问题，因为旋转操作涉及的操作可能导致锁竞争。
  2. 红黑树的平衡维护需要复杂的旋转操作，增加了实现和维护的复杂度。
  3. 红黑树的平均性能和最坏情况下的性能差距较大。

总的来说，跳表通常适用于需要高并发性能、内存充足、插入和删除操作较频繁的场景。而红黑树适用于内存受限、需要稳定性能且不关注高并发性能的场景。在选择数据结构时，需要根据具体的应用需求和场景来进行权衡和选择。

**命令示例**

```shell
redis 127.0.0.1:6379> ZADD runoobkey 1 redis
(integer) 1
redis 127.0.0.1:6379> ZADD runoobkey 2 mongodb
(integer) 1
redis 127.0.0.1:6379> ZADD runoobkey 3 mysql
(integer) 1
redis 127.0.0.1:6379> ZADD runoobkey 3 mysql
(integer) 0
redis 127.0.0.1:6379> ZADD runoobkey 4 mysql
(integer) 0
redis 127.0.0.1:6379> ZRANGE runoobkey 0 10 WITHSCORES

1) "redis"
2) "1"
3) "mongodb"
4) "2"
5) "mysql"
6) "4"

```

**注意点**

- 集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)其实不太准确。其实在redis sorted sets里面当items内容大于64的时候同时使用了hash和skiplist两种设计实现。这也会为了排序和查找性能做的优化。所以如上可知： 添加和删除都需要修改skiplist，所以复杂度为O(log(n))。 但是如果仅仅是查找元素的话可以直接使用hash，其复杂度为O(1) 。其他的range操作复杂度一般为O(log(n))；当然如果是小于64的时候，因为是采用了ziplist的设计，其时间复杂度为O(n)

## 高级结构

### HyperLogLog

> Redis 在 2.8.9 版本添加了 HyperLogLog 结构。
>
> Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。
>
> 在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基 数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。
>
> 但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。

**示例**

```shell
redis 127.0.0.1:6379> PFADD runoobkey "redis"

1) (integer) 1

redis 127.0.0.1:6379> PFADD runoobkey "mongodb"

1) (integer) 1

redis 127.0.0.1:6379> PFADD runoobkey "mysql"

1) (integer) 1

redis 127.0.0.1:6379> PFCOUNT runoobkey

(integer) 3
```



### GEO

> Redis GEO 主要用于存储地理位置信息，并对存储的信息进行操作，该功能在 Redis 3.2 版本新增。
>
> Redis GEO 操作方法有：
>
> - geoadd：添加地理位置的坐标。
> - geopos：获取地理位置的坐标。
> - geodist：计算两个位置之间的距离。
> - georadius：根据用户给定的经纬度坐标来获取指定范围内的地理位置集合。
> - georadiusbymember：根据储存在位置集合里面的某个地点获取指定范围内的地理位置集合。
> - geohash：返回一个或多个位置对象的 geohash 值。

### Stream

> Redis Stream 是 Redis 5.0 版本新增加的数据结构。
>
> Redis Stream 主要用于消息队列（MQ，Message Queue），Redis 本身是有一个 Redis 发布订阅 (pub/sub) 来实现消息队列的功能，但它有个缺点就是消息无法持久化，如果出现网络断开、Redis 宕机等，消息就会被丢弃。
>
> 简单来说发布订阅 (pub/sub) 可以分发消息，但无法记录历史消息。
>
> 而 Redis Stream 提供了消息的持久化和主备复制功能，可以让任何客户端访问任何时刻的数据，并且能记住每一个客户端的访问位置，还能保证消息不丢失。
>
> Redis Stream 的结构如下所示，它有一个消息链表，将所有加入的消息都串起来，每个消息都有一个唯一的 ID 和对应的内容：

![截屏2023-10-14 09.37.49](/Users/xiangjianhang/Downloads/LN/Redis/截屏2023-10-14 09.37.49.png)

每个 Stream 都有唯一的名称，它就是 Redis 的 key，在我们首次使用 xadd 指令追加消息时自动创建。

上图解析：

- **Consumer Group** ：消费组，使用 XGROUP CREATE 命令创建，一个消费组有多个消费者(Consumer)。
- **last_delivered_id** ：游标，每个消费组会有个游标 last_delivered_id，任意一个消费者读取了消息都会使游标 last_delivered_id 往前移动。
- **pending_ids** ：消费者(Consumer)的状态变量，作用是维护消费者的未确认的 id。 pending_ids 记录了当前已经被客户端读取的消息，但是还没有 ack (Acknowledge character：确认字符）。

**消息队列相关命令：**

- **XADD** - 添加消息到末尾
- **XTRIM** - 对流进行修剪，限制长度
- **XDEL** - 删除消息
- **XLEN** - 获取流包含的元素数量，即消息长度
- **XRANGE** - 获取消息列表，会自动过滤已经删除的消息
- **XREVRANGE** - 反向获取消息列表，ID 从大到小
- **XREAD** - 以阻塞或非阻塞方式获取消息列表

**消费者组相关命令：**

- **XGROUP CREATE** - 创建消费者组
- **XREADGROUP GROUP** - 读取消费者组中的消息
- **XACK** - 将消息标记为"已处理"
- **XGROUP SETID** - 为消费者组设置新的最后递送消息ID
- **XGROUP DELCONSUMER** - 删除消费者
- **XGROUP DESTROY** - 删除消费者组
- **XPENDING** - 显示待处理消息的相关信息
- **XCLAIM** - 转移消息的归属权
- **XINFO** - 查看流和消费者组的相关信息；
- **XINFO GROUPS** - 打印消费者组的信息；
- **XINFO STREAM** - 打印流信息

#### BitMap

> Redis中的Bitmap是一种特殊的数据结构，用于位操作和位图存储。它通常用于解决需要高效存储和查询二进制状态信息的场景，例如用户在线状态、用户签到、活动参与情况等。
>
> 

**以下是对Redis中Bitmap的介绍：**

1. **位图数据结构**：Redis的Bitmap实际上是一个由二进制位组成的字符串，每个位只能存储0或1。这样的数据结构非常紧凑，适用于大规模的位存储。

2. **位的设置和获取**：你可以通过Redis提供的命令来设置和获取位的值。比如，你可以使用`SETBIT`命令设置指定位的值，`GETBIT`命令获取位的值。

3. **位操作**：Redis支持各种位操作，如AND、OR、XOR、NOT等。这些操作可以对不同位图进行逻辑运算，用于比较和计算。

4. **位计数**：Redis提供`BITCOUNT`命令，可以统计位图中值为1的位的数量。这在统计用户在线人数等场景中非常有用。

5. **位图的有效期**：你可以为位图设置有效期，类似于普通的Redis键。一旦位图过期，其中的数据将被清除。

6. **位图的应用**：
   - 用户在线状态：每个用户使用一个位来表示在线或离线状态。
   - 用户签到：每一天使用一个位来表示用户是否签到。
   - 布隆过滤器：Bitmap可以用于实现一个简单的布隆过滤器，用于查找元素是否存在。

7. **注意事项**：
   - 由于Redis中的位图是紧凑的，它们可能会占用较小的内存。但要注意，当位图非常大时，内存占用也会相应增加，需谨慎使用。
   - 位图一般用于表示开关状态或标记，不适合存储大型数据。



**示例**

1. **SETBIT**：设置位的值
   - `SETBIT key offset value`：将key对应的位图中的指定偏移(offset)的位设置为value (0或1)。
2. **GETBIT**：获取位的值
   - `GETBIT key offset`：返回key对应的位图中指定偏移(offset)的位的值 (0或1)。
3. **BITCOUNT**：统计位图中值为1的位的数量
   - `BITCOUNT key [start] [end]`：统计key对应的位图中，从start到end范围内值为1的位的数量。如果不提供start和end，默认统计整个位图。
4. **BITOP**：对多个位图执行位运算
   - `BITOP operation destkey key [key ...]`：对多个位图执行位运算，并将结果保存在destkey中。操作(operation)可以是AND、OR、XOR、NOT等。
5. **BITPOS**：查找第一个设置或清除的位
   - `BITPOS key bit [start] [end]`：查找从start到end范围内第一个设置或清除的位(bit)的位置。
6. **BITFIELD**：批量操作位字段
   - `BITFIELD key [GET type offset] [SET type offset value]`：执行一系列位操作，可以用于设置、获取、修改指定位域的值。

## 发布订阅模式

**案例**

微信班级群`class:20170101`，发布订阅模型

**学生 A B C:**

------

**学生C:**

订阅一个`主题`名叫： `class:20170101`

```bash
127.0.0.1:6379> SUBSCRIBE class:20170101
Reading messages... (press Ctrl-C to quit)
1) "subscribe"
2) "redisChat"
3) (integer) 1
```

**学生A:**

针对 `class:20170101` 主题发送 消息，那么所有订阅该主题的用户都能够收到该数据。

```cpp
127.0.0.1:6379> PUBLISH class:20170101 "i love peace!"
(integer) 1
```

**学生B:**

针对 `class:20170101` 主题发送 消息，那么所有订阅该主题的用户都能够收到该数据。

```cpp
127.0.0.1:6379> PUBLISH class:20170101 "go to hell"
(integer) 1
```

最后学生C会收到 A 和 B 发送过来的消息。

```cpp
python@ubuntu:~$ redis-cli 
127.0.0.1:6379> SUBSCRIBE class:20170101
Reading messages... (press Ctrl-C to quit)
1) "subscribe"
2) "class:20170101"
3) (integer) 1
1) "message"
2) "class:20170101"
3) "i love peace!"
1) "message"
2) "class:20170101"
3) "i love peace!"
1) "message"
2) "class:20170101"
3) "go to hell"
```

## Redis 事务

Redis事务允许一组命令在单一步骤中执行。事务有两个属性，说明如下：

- 事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。
- Redis事务是原子的。原子意味着要么所有的命令都执行，要么都不执行；

一个事务从开始到执行会经历以下三个阶段：

- 开始事务
- 命令入队
- 执行事务

```bash
redis 127.0.0.1:6379> MULTI
OK
List of commands here
redis 127.0.0.1:6379> EXEC
```

**案例**

银行转账，邓超给宝强转账1万元：

```bash
127.0.0.1:6379> set dengchao 60000
OK
127.0.0.1:6379> set wangbaoqiang 200
OK
127.0.0.1:6379> multi
OK
127.0.0.1:6379> INCRBY dengchao -10000
QUEUED
127.0.0.1:6379> INCRBY wangbaoqiang 10000
QUEUED
127.0.0.1:6379> EXEC
1) (integer) 50000
2) (integer) 10200
127.0.0.1:6379>
```

## Redis 数据备份与恢复

### 原理



### 案例

Redis SAVE 命令用于创建当前数据库的备份。

**语法**

redis Save 命令基本语法如下：

```
redis 127.0.0.1:6379> SAVE
```

**实例**

```
redis 127.0.0.1:6379> SAVE 
OK
```

该命令将在 redis 安装目录中创建dump.rdb文件。

**恢复数据**

如果需要恢复数据，只需将备份文件 (dump.rdb) 移动到 redis 安装目录并启动服务即可。获取 redis 目录可以使用 CONFIG 命令，如下所示：

```
redis 127.0.0.1:6379> CONFIG GET dir
1) "dir"
2) "/home/python"
```

以上命令 CONFIG GET dir 输出的 redis 安装目录为 /home/python。

**Bgsave**

创建 redis 备份文件也可以使用命令 BGSAVE，该命令在后台执行。

**实例**

```
127.0.0.1:6379> BGSAVE

Background saving started
```

## Redis 分区

分区是分割数据到多个Redis实例的处理过程，因此每个实例只保存key的一个子集。

**分区的优势**

- 通过利用多台计算机内存的和值，允许我们构造更大的数据库。
- 通过多核和多台计算机，允许我们扩展计算能力；通过多台计算机和网络适配器，允许我们扩展网络带宽。

**分区的不足**

redis的一些特性在分区方面表现的不是很好：

- 涉及多个key的操作通常是不被支持的。举例来说，当两个set映射到不同的redis实例上时，你就不能对这两个set执行交集操作。
- 涉及多个key的redis事务不能使用。
- 当使用分区时，数据处理较为复杂，比如你需要处理多个rdb/aof文件，并且从多个实例和主机备份持久化文件。
- 增加或删除容量也比较复杂。redis集群大多数支持在运行时增加、删除节点的透明数据平衡的能力，但是类似于客户端分区、代理等其他系统则不支持这项特性。然而，一种叫做presharding的技术对此是有帮助的。

**分区类型**

Redis 有两种类型分区。 假设有4个Redis实例 R0，R1，R2，R3，和类似user:1，user:2这样的表示用户的多个key，对既定的key有多种不同方式来选择这个key存放在哪个实例中。也就是说，有不同的系统来映射某个key到某个Redis服务。

**范围分区**

最简单的分区方式是按范围分区，就是映射一定范围的对象到特定的Redis实例。

比如，ID从0到10000的用户会保存到实例R0，ID从10001到 20000的用户会保存到R1，以此类推。

这种方式是可行的，并且在实际中使用，不足就是要有一个区间范围到实例的映射表。这个表要被管理，同时还需要各 种对象的映射表，通常对Redis来说并非是好的方法。

**哈希分区**

另外一种分区方法是hash分区。这对任何key都适用，也无需是object_name:这种形式，像下面描述的一样简单：

- 用一个hash函数将key转换为一个数字，比如使用crc32 hash函数。对key foobar执行crc32(foobar)会输出类似93024922的整数。
- 对这个整数取模，将其转化为0-3之间的数字，就可以将这个整数映射到4个Redis实例中的一个了。93024922 % 4 = 2，就是说key foobar应该被存到R2实例中。注意：取模操作是取除的余数，通常在多种编程语言中用%操作符实现。

## Redis 管道技术

Redis是一种基于客户端-服务端模型以及请求/响应协议的TCP服务。这意味着通常情况下一个请求会遵循以下步骤：

- 客户端向服务端发送一个查询请求，并监听Socket返回，通常是以阻塞模式，等待服务端响应。
- 服务端处理命令，并将结果返回给客户端。

Redis 管道技术可以在服务端未响应时，客户端可以继续向服务端发送请求，并最终一次性读取所有服务端的响应。

**实例**

查看 redis 管道，只需要启动 redis 实例并输入以下命令：

```
$(echo -en "PING\r\n SET runoobkey redis\r\nGET runoobkey\r\nINCR visitor\r\nINCR visitor\r\nINCR visitor\r\n"; sleep 10) | nc localhost 6379

+PONG
+OK
redis
:1
:2
:3
```

以上实例中我们通过使用 **PING** 命令查看redis服务是否可用， 之后我们设置了 runoobkey 的值为 redis，然后我们获取 runoobkey 的值并使得 visitor 自增 3 次。

在返回的结果中我们可以看到这些命令一次性向 redis 服务提交，并最终一次性读取所有服务端的响应

## Redis持久化策略

Redis支持RDB持久化、AOF持久化、RDB-AOF混合持久化这三种持久化方式。

### RDB

RDB(Redis Database)是Redis默认采用的持久化方式，它以快照的形式将进程数据持久化到硬盘中。RDB会创建一个经过压缩的二进制文件，文件以“.rdb”结尾，内部存储了各个数据库的键值对数据等信息。RDB持久化的触发方式有两种：

- 手动触发：通过SAVE或BGSAVE命令触发RDB持久化操作，创建“.rdb”文件；
- 自动触发：通过配置选项，让服务器在满足指定条件时自动执行BGSAVE命令。

其中，SAVE命令执行期间，Redis服务器将阻塞，直到“.rdb”文件创建完毕为止。而BGSAVE命令是异步版本的SAVE命令，它会使用Redis服务器进程的子进程，创建“.rdb”文件。BGSAVE命令在创建子进程时会存在短暂的阻塞，之后服务器便可以继续处理其他客户端的请求。总之，BGSAVE命令是针对SAVE阻塞问题做的优化，Redis内部所有涉及RDB的操作都采用BGSAVE的方式，而SAVE命令已经废弃！



RDB持久化的优缺点如下：

- 优点：RDB生成紧凑压缩的二进制文件，体积小，使用该文件恢复数据的速度非常快；

- 缺点：BGSAVE每次运行都要执行fork操作创建子进程，属于重量级操作，不宜频繁执行，

  所以RDB持久化没办法做到实时的持久化。

### AOF

AOF（Append Only File），解决了数据持久化的实时性，是目前Redis持久化的主流方式。AOF以独立日志的方式，记录了每次写入命令，重启时再重新执行AOF文件中的命令来恢复数据。AOF的工作流程包括：命令写入（append）、文件同步（sync）、文件重写（rewrite）、重启加载（load），如下图：

![截屏2023-10-14 13.13.50](/Users/xiangjianhang/Downloads/LN/Redis/截屏2023-10-14 13.13.50.png)

AOF以文本协议格式写入命令，如：

```
*3\r\n$3\r\nset\r\n$5\r\nhello\r\n$5\r\nworld\r\n
```

文本协议格式具有如下的优点：

1. 文本协议具有很好的兼容性；
2. 直接采用文本协议格式，可以避免二次处理的开销；
3. 文本协议具有可读性，方便直接修改和处理。

AOF持久化的文件同步机制：

为了提高程序的写入性能，现代操作系统会把针对硬盘的多次写操作优化为一次写操作。

1. 当程序调用write对文件写入时，系统不会直接把书记写入硬盘，而是先将数据写入内存的缓冲区中；
2. 当达到特定的时间周期或缓冲区写满时，系统才会执行flush操作，将缓冲区中的数据冲洗至硬盘中；

这种优化机制虽然提高了性能，但也给程序的写入操作带来了不确定性。

1. 对于AOF这样的持久化功能来说，冲洗机制将直接影响AOF持久化的安全性；
2. 为了消除上述机制的不确定性，Redis向用户提供了appendfsync选项，来控制系统冲洗AOF的频率；
3. Linux的glibc提供了fsync函数，可以将指定文件强制从缓冲区刷到硬盘，上述选项正是基于此函数。

AOF持久化的优缺点如下：

- 优点：与RDB持久化可能丢失大量的数据相比，AOF持久化的安全性要高很多。通过使用everysec选项，用户可以将数据丢失的时间窗口限制在1秒之内。
- 缺点：AOF文件存储的是协议文本，它的体积要比二进制格式的”.rdb”文件大很多。AOF需要通过执行AOF文件中的命令来恢复数据库，其恢复速度比RDB慢很多。AOF在进行重写时也需要创建子进程，在数据库体积较大时将占用大量资源，会导致服务器的短暂阻塞。

### RDB-AOF混合持久化

Redis从4.0开始引入RDB-AOF混合持久化模式，这种模式是基于AOF持久化构建而来的。用户可以通过配置文件中的“aof-use-rdb-preamble yes”配置项开启AOF混合持久化。Redis服务器在执行AOF重写操作时，会按照如下原则处理数据：

- 像执行BGSAVE命令一样，根据数据库当前的状态生成相应的RDB数据，并将其写入AOF文件中；
- 对于重写之后执行的Redis命令，则以协议文本的方式追加到AOF文件的末尾，即RDB数据之后。

通过使用RDB-AOF混合持久化，用户可以同时获得RDB持久化和AOF持久化的优点，服务器既可以通过AOF文件包含的RDB数据来实现快速的数据恢复操作，又可以通过AOF文件包含的AOF数据来将丢失数据的时间窗口限制在1s之内。

## Redis高可用

### 哨兵

Redis Sentinel（哨兵）是一个分布式架构，它包含若干个哨兵节点和数据节点。每个哨兵节点会对数据节点和其余的哨兵节点进行监控，当发现节点不可达时，会对节点做下线标识。如果被标识的是主节点，它就会与其他的哨兵节点进行协商，当多数哨兵节点都认为主节点不可达时，它们便会选举出一个哨兵节点来完成自动故障转移的工作，同时还会将这个变化实时地通知给应用方。整个过程是自动的，不需要人工介入，有效地解决了Redis的高可用问题！

一组哨兵可以监控一个主节点，也可以同时监控多个主节点，两种情况的拓扑结构如下图：

![image-20231014145852478](/Users/xiangjianhang/Downloads/LN/Redis/image-20231014145852478.png)



**哨兵节点包含如下的特征**：

1. 哨兵节点会定期监控数据节点，其他哨兵节点是否可达；
2. 哨兵节点会将故障转移的结果通知给应用方；
3. 哨兵节点可以将从节点晋升为主节点，并维护后续正确的主从关系；
4. 哨兵模式下，客户端连接的是哨兵节点集合，从中获取主节点信息；
5. 节点的故障判断是由多个哨兵节点共同完成的，可有效地防止误判；
6. 哨兵节点集合是由多个哨兵节点组成的，即使个别哨兵节点不可用，整个集合依然是健壮的；
7. 哨兵节点也是独立的Redis节点，是特殊的Redis节点，它们不存储数据，只支持部分命令。

### 集群

Redis集群采用虚拟槽分区来实现数据分片，它把所有的键根据哈希函数映射到0-16383整数槽内，计算公式为slot=CRC16(key)&16383，每一个节点负责维护一部分槽以及槽所映射的键值数据。虚拟槽分区具有如下特点：

1. 解耦数据和节点之间的关系，简化了节点扩容和收缩的难度；
2. 节点自身维护槽的映射关系，不需要客户端或者代理服务维护槽分区元数据；
3. 支持节点、槽、键之间的映射查询，用于数据路由，在线伸缩等场景。

**Redis集群中数据的分片逻辑如下图**：

![image-20231014150146428](/Users/xiangjianhang/Downloads/LN/Redis/image-20231014150146428.png)

**Redis集群方案在扩展了Redis处理能力的同时，也带来了一些使用上的限制：**

1. key批量操作支持有限。如mset、mget，目前只支持具有相同slot值的key执行批量操作。对于映射为不同slot值的key由于执行mset、mget等操作可能存在于多个节点上所以不被支持。
2. key事务操作支持有限。同理只支持多key在同一节点上的事务操作，当多个key分布在不同的节点上时无法使用事务功能。
3. key作为数据分区的最小粒度，因此不能将一个大的键值对象（如hash、list等）映射到不同的节点。
4. 不支持多数据库空间。单机下的Redis可以支持16个数据库，集群模式下只能使用一个数据库空间，即DB0。
5. 复制结构只支持一层，从节点只能复制主节点，不支持嵌套树状复制结构。

**集群的通信**

Redis集群采用P2P的Gossip（流言）协议，Gossip协议的工作原理就是节点彼此不断通信交换信息，一段时间后所有的节点都会知道集群完整的信息，这种方式类似流言传播。通信的大致过程如下：

1. 集群中每个节点都会单独开辟一个TCP通道，用于节点之间彼此通信，通信端口号在基础端口号上加10000；
2. 每个节点再固定周期内通过特定规则选择几个节点发送ping消息；
3. 接收ping消息的节点用pong消息作为响应。

其中，Gossip协议的主要职责就是信息交换，而信息交换的载体就是节点彼此发送的Gossip消息，Gossip消息分为：meet消息、ping消息、pong消息、fail消息等。

- meet消息：用于通知新节点加入，消息发送者通知接受者加入到当前集群。meet消息通信正常完成后，接收节点会加入到集群中并进行周期性的ping、pong消息交换。
- ping消息：集群内交换最频繁的消息，集群内每个节点每秒向多个其他节点发送ping消息，用于检测节点是否在线和交换彼此状态信息。ping消息封装了自身节点和一部分其他节点的状态数据。
- pong消息：当接收到meet、ping消息时，作为响应消息回复给发送方确认消息正常通信。pong消息内封装了自身状态数据，节点也可以向集群内广播自身的pong消息来通知整个集群对自身状态进行更新。
- fail消息：当节点判定集群内另一个节点下线时，会向集群内广播一个fail消息，其他节点接收到fail消息之后把对应节点更新为下线状态。

### 主从同步

从2.8版本开始，Redis使用psync命令完成主从数据同步，同步过程分为全量复制和部分复制。全量复制一般用于初次复制的场景，部分复制则用于处理因网络中断等原因造成数据丢失的场景。psync命令需要以下参数的支持：

1. 复制偏移量：主节点处理写命令后，会把命令长度做累加记录，从节点在接收到写命令后，也会做累加记录；从节点会每秒钟上报一次自身的复制偏移量给主节点，而主节点则会保存从节点的复制偏移量。
2. 积压缓冲区：保存在主节点上的一个固定长度的队列，默认大小为1M，当主节点有连接的从节点时被创建；主节点处理写命令时，不但会把命令发送给从节点，还会写入积压缓冲区；缓冲区是先进先出的队列，可以保存最近已复制的数据，用于部分复制和命令丢失的数据补救。
3. 主节点运行ID：每个Redis节点启动后，都会动态分配一个40位的十六进制字符串作为运行ID；如果使用IP和端口的方式标识主节点，那么主节点重启变更了数据集（RDB/AOF），从节点再基于复制偏移量复制数据将是不安全的，因此当主节点的运行ID变化后，从节点将做全量复制。

psync命令的执行过程以及返回结果，如下图：

![image-20231014150446882](/Users/xiangjianhang/Downloads/LN/Redis/image-20231014150446882.png)

#### 全量复制

![946920CB89AE5D191202B12E9FE9F4F7](/Users/xiangjianhang/Downloads/LN/Redis/946920CB89AE5D191202B12E9FE9F4F7.png)

#### 部分复制

![38A020497C3D4B30EF561E8415EAFAB1](/Users/xiangjianhang/Downloads/LN/Redis/38A020497C3D4B30EF561E8415EAFAB1.png)